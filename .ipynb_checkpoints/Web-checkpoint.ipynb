{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanhtml(raw_html):\n",
    "  cleanr = re.compile('<.*?>')\n",
    "  cleantext = re.sub(cleanr, '', raw_html)\n",
    "  regex = re.compile('[^A-Za-zА-Яа-я]')\n",
    "  cleantext = regex.sub(' ', cleantext)\n",
    "  return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isvotes(tag):\n",
    "    return tag.has_attr('class') and tag.has_attr('onclick') and not tag.has_attr('href') and not tag.has_attr('type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document(id):\n",
    "    page = requests.get('https://habr.com/ru/post/' + str(id) + '/')\n",
    "    soup = BeautifulSoup(page.text, 'html5lib')\n",
    "    info = []\n",
    "    if soup.find(\"span\", class_= \"post__title-text\"):\n",
    "        #title\n",
    "        info.append(soup.find(\"span\", class_= \"post__title-text\").text)\n",
    "        #text\n",
    "        text = soup.find(\"div\", class_=\"post__text post__text-html\").text\n",
    "        info.append(cleanhtml(text).split())\n",
    "        #year\n",
    "        info.append(int(soup.find(\"span\", class_= \"post__time\").text.split()[2]))\n",
    "        #tags\n",
    "        tagsshit = soup.find_all(\"a\", class_=\"inline-list__item-link hub-link\")\n",
    "        tags = []\n",
    "        for i in range(len(tagsshit)):\n",
    "            tags.append(tagsshit[i].text)\n",
    "        info.append(tags)\n",
    "        #votes\n",
    "        a = soup.find(isvotes).text\n",
    "        if a[0] == '–':\n",
    "            b = int(a[1:])\n",
    "            info.append(-b)\n",
    "        else:\n",
    "            info.append(int(a))\n",
    "        #views\n",
    "        a = soup.find(\"div\", class_=\"post-stats__views\").text.strip()\n",
    "        if 'k' in a:\n",
    "            views = float(a[:-1].replace(',', '.')) * 1000\n",
    "        else:\n",
    "            views = int(a)\n",
    "        info.append(views)\n",
    "        #bookmarks\n",
    "        info.append(int(soup.find(\"span\", class_=\"bookmark__counter js-favs_count\").text))\n",
    "        #comments\n",
    "        comment1 = soup.find_all(\"div\", class_=\"comment__message\")\n",
    "        comments = []\n",
    "        for i in range(len(comment1)):\n",
    "            comments.append(comment1[i].text)\n",
    "        info.append(comments)\n",
    "    else:\n",
    "        info.append('NaN')\n",
    "    print(id)\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(a, columns=['title', 'text', 'year', 'tags', 'votes', 'views', 'bookmarks', 'comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('habr.csv')\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "from google.colab import files\n",
    "files.download('habr.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
